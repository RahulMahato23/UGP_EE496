{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "#  POST-SWEEP ANALYSIS – load existing .pth checkpoints\n",
    "# --------------------------------------------------------------\n",
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "import torchvision, torchvision.transforms as transforms\n",
    "import timm, numpy as np, pandas as pd, json, os, glob\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "# ---------- 0. Paths ----------\n",
    "OUTPUT_DIR = \"/home/akshy_grp12\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---------- 1. Data (same as training) ----------\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))\n",
    "])\n",
    "test_set   = torchvision.datasets.CIFAR10(root='/home/akshy_grp12/dataset',\n",
    "                                          train=False, download=True,\n",
    "                                          transform=transform_test)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=128,\n",
    "                                          shuffle=False, num_workers=2,\n",
    "                                          pin_memory=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 904 checkpoints\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---------- 2. Helper: create model (same architecture) ----------\n",
    "def create_vit_model(depth, mlp_ratio, embed_dim=192, num_heads=3, drop_path_rate=0.1):\n",
    "    return timm.create_model(\n",
    "        'vit_tiny_patch16_224', pretrained=False, num_classes=10,\n",
    "        img_size=32, patch_size=4,\n",
    "        embed_dim=embed_dim, depth=depth, num_heads=num_heads,\n",
    "        mlp_ratio=mlp_ratio, qkv_bias=True,\n",
    "        drop_path_rate=drop_path_rate\n",
    "    )\n",
    "\n",
    "# ---------- 3. Evaluation (clean test) ----------\n",
    "def evaluate_clean(model):\n",
    "    model.eval()\n",
    "    correct = total = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            pred = model(x).max(1)[1]\n",
    "            correct += pred.eq(y).sum().item()\n",
    "            total   += y.size(0)\n",
    "    return 100. * correct / total\n",
    "\n",
    "# ---------- 4. Find *all* checkpoints ----------\n",
    "pattern = f\"{OUTPUT_DIR}/outputvit_d*_mlp*_noise*.pth\"\n",
    "ckpt_paths = sorted(glob.glob(pattern))\n",
    "print(f\"Found {len(ckpt_paths)} checkpoints\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating checkpoints: 100%|██████████| 904/904 [35:12<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Master CSV saved → /home/akshy_grp12/vit_grid_results.csv\n",
      "Line plot → /home/akshy_grp12/vit_line.png\n",
      "Surface → /home/akshy_grp12/surface_noise_0.0.png\n",
      "Surface → /home/akshy_grp12/surface_noise_0.05.png\n",
      "Surface → /home/akshy_grp12/surface_noise_0.1.png\n",
      "Surface → /home/akshy_grp12/surface_noise_0.15.png\n",
      "Surface → /home/akshy_grp12/surface_noise_0.2.png\n",
      "Surface → /home/akshy_grp12/surface_noise_0.25.png\n",
      "Surface → /home/akshy_grp12/surface_noise_0.3.png\n",
      "Surface → /home/akshy_grp12/surface_noise_0.35.png\n",
      "Surface → /home/akshy_grp12/surface_noise_0.4.png\n",
      "Surface → /home/akshy_grp12/surface_noise_0.45.png\n",
      "Metadata JSON saved\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---------- 5. Parse filename → hyper-params ----------\n",
    "import re\n",
    "def parse_ckpt(path):\n",
    "    # vit_d16_mlp4.5_noise0.0.pth  → depth=16, mlp=4.5, noise=0.0\n",
    "    m = re.search(r'outputvit_d(\\d+)_mlp([\\d\\.]+)_noise([\\d\\.]+)\\.pth', os.path.basename(path))\n",
    "    if not m: raise ValueError(path)\n",
    "    depth = int(m.group(1))\n",
    "    mlp   = float(m.group(2))\n",
    "    noise = float(m.group(3))\n",
    "    return depth, mlp, noise\n",
    "\n",
    "# ---------- 6. Evaluate every checkpoint ----------\n",
    "rows = []\n",
    "for p in tqdm(ckpt_paths, desc=\"Evaluating checkpoints\"):\n",
    "    depth, mlp, noise = parse_ckpt(p)\n",
    "    model = create_vit_model(depth=depth, mlp_ratio=mlp)\n",
    "    model.load_state_dict(torch.load(p, map_location=device))\n",
    "    model.to(device)\n",
    "\n",
    "    acc = evaluate_clean(model)                 # clean test accuracy\n",
    "    params = sum(par.numel() for par in model.parameters())\n",
    "\n",
    "    rows.append({\n",
    "        \"train_noise\": noise,\n",
    "        \"depth\": depth,\n",
    "        \"mlp_ratio\": mlp,\n",
    "        \"embed_dim\": 192,\n",
    "        \"num_heads\": 3,\n",
    "        \"params\": params,\n",
    "        \"epochs\": 30,\n",
    "        \"test_noise\": 0.0,\n",
    "        \"accuracy\": acc\n",
    "    })\n",
    "    del model; torch.cuda.empty_cache()\n",
    "\n",
    "# ---------- 7. Save master CSV ----------\n",
    "master_csv = f\"{OUTPUT_DIR}/vit_grid_results.csv\"\n",
    "pd.DataFrame(rows).to_csv(master_csv, index=False)\n",
    "print(f\"\\nMaster CSV saved → {master_csv}\")\n",
    "\n",
    "# ---------- 8. Quick line-plot (depth vs noise) ----------\n",
    "def plot_line(df):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    for d in sorted(df['depth'].unique()):\n",
    "        sub = df[df['depth']==d].sort_values('train_noise')\n",
    "        plt.plot(sub['train_noise'], sub['accuracy'], 'o-', label=f'Depth {d}')\n",
    "    plt.xlabel('Train Noise'); plt.ylabel('Clean Test Acc (%)')\n",
    "    plt.title('ViT Accuracy vs Training Noise')\n",
    "    plt.legend(); plt.grid(alpha=.3)\n",
    "    out = f\"{OUTPUT_DIR}/vit_line.png\"\n",
    "    plt.savefig(out, dpi=300, bbox_inches='tight'); plt.close()\n",
    "    print(f\"Line plot → {out}\")\n",
    "\n",
    "plot_line(pd.DataFrame(rows))\n",
    "\n",
    "# ---------- 9. Surface plots (one per noise level) ----------\n",
    "def surface_plots(df):\n",
    "    df = df[df['test_noise']==0.0]\n",
    "    for nv in sorted(df['train_noise'].unique()):\n",
    "        sub = df[df['train_noise']==nv]\n",
    "        depths = sorted(sub['depth'].unique())\n",
    "        mlps   = sorted(sub['mlp_ratio'].unique())\n",
    "\n",
    "        # pivot → Z matrix\n",
    "        Z = sub.pivot(index='mlp_ratio', columns='depth', values='accuracy')\n",
    "        Z = Z.reindex(mlps).reindex(depths, axis=1).values\n",
    "\n",
    "        fig = plt.figure(figsize=(7,5))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        X, Y = np.meshgrid(depths, mlps)\n",
    "        ax.plot_surface(X, Y, Z, cmap='viridis', edgecolor='none', alpha=0.9)\n",
    "        ax.set_xlabel('Depth'); ax.set_ylabel('MLP Ratio'); ax.set_zlabel('Acc (%)')\n",
    "        ax.set_title(f'Accuracy Surface – train_noise={nv}')\n",
    "        out = f\"{OUTPUT_DIR}/surface_noise_{nv}.png\"\n",
    "        plt.savefig(out, dpi=300, bbox_inches='tight'); plt.close()\n",
    "        print(f\"Surface → {out}\")\n",
    "\n",
    "surface_plots(pd.DataFrame(rows))\n",
    "\n",
    "# ---------- 10. Save minimal metadata ----------\n",
    "metadata = {\n",
    "    \"date\": datetime.now().isoformat(),\n",
    "    \"grid\": {\n",
    "        \"noise\": sorted(pd.DataFrame(rows)['train_noise'].unique().tolist()),\n",
    "        \"depth\": sorted(pd.DataFrame(rows)['depth'].unique().tolist()),\n",
    "        \"mlp\":   sorted(pd.DataFrame(rows)['mlp_ratio'].unique().tolist())\n",
    "    },\n",
    "    \"total_models\": len(rows)\n",
    "}\n",
    "with open(f\"{OUTPUT_DIR}/experiment_metadata.json\", \"w\") as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "print(\"Metadata JSON saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More vivid graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================\n",
    "#  POST-SWEEP: Visualization + Full Metrics + Interactive 3D\n",
    "# ==============================================================\n",
    "import torch, torch.nn as nn\n",
    "import torchvision, torchvision.transforms as transforms\n",
    "import timm, numpy as np, pandas as pd, json, os, glob, re\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_fscore_support, accuracy_score, confusion_matrix\n",
    "import plotly.graph_objects as go\n",
    "from scipy.stats import sem, t\n",
    "\n",
    "# ------------------- 0. Paths & Device -------------------\n",
    "# OUTPUT_DIR = \"/home/akshy_grp12/output\"\n",
    "# os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(f\"Using {device}\")\n",
    "\n",
    "# ------------------- 1. Data Loaders -------------------\n",
    "# transform_clean = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))\n",
    "# ])\n",
    "# test_set = torchvision.datasets.CIFAR10(root='/home/akshy_grp12/dataset', train=False,\n",
    "#                                         download=True, transform=transform_clean)\n",
    "# test_loader = torch.utils.data.DataLoader(test_set, batch_size=128,\n",
    "#                                           shuffle=False, num_workers=2, pin_memory=True)\n",
    "###################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/akshy_grp12/.venv/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 904 checkpoints\n",
      "Evaluating all models with full metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Models:  48%|████▊     | 433/904 [2:45:09<3:04:38, 23.52s/it]"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# For visualization: get 2 samples per class\n",
    "class_to_idx = {name: i for i, name in enumerate(test_set.classes)}\n",
    "samples_per_class = {i: [] for i in range(10)}\n",
    "for img, label in test_set:\n",
    "    if len(samples_per_class[label]) < 2:\n",
    "        samples_per_class[label].append(img)\n",
    "    if all(len(v) == 2 for v in samples_per_class.values()):\n",
    "        break\n",
    "vis_images = [img for cls in samples_per_class.values() for img in cls]  # 20 images\n",
    "vis_labels = [i for i in range(10) for _ in range(2)]\n",
    "\n",
    "# ------------------- 2. Noise Function -------------------\n",
    "CIFAR_MEAN = (0.4914, 0.4822, 0.4465)\n",
    "CIFAR_STD  = (0.2470, 0.2435, 0.2616)\n",
    "_inv = transforms.Normalize(mean=[-m/s for m,s in zip(CIFAR_MEAN, CIFAR_STD)],\n",
    "                            std=[1/s for s in CIFAR_STD])\n",
    "_norm = transforms.Normalize(CIFAR_MEAN, CIFAR_STD)\n",
    "\n",
    "def add_noise_in_rgb_space(x, sigma):\n",
    "    if x.dim() == 3: x = x.unsqueeze(0)\n",
    "    x_rgb = torch.clamp(_inv(x), 0., 1.)\n",
    "    noise = sigma * torch.randn_like(x_rgb)\n",
    "    x_noisy = torch.clamp(x_rgb + noise, 0., 1.)\n",
    "    return _norm(x_noisy).nan_to_num_()\n",
    "\n",
    "def denormalize(tensor):\n",
    "    tensor = tensor.clone()\n",
    "    for t, m, s in zip(tensor, CIFAR_MEAN, CIFAR_STD):\n",
    "        t.mul_(s).add_(m)\n",
    "    return torch.clamp(tensor, 0, 1)\n",
    "\n",
    "# ------------------- 3. Model Creation -------------------\n",
    "def create_vit_model(depth, mlp_ratio):\n",
    "    return timm.create_model('vit_tiny_patch16_224', pretrained=False, num_classes=10,\n",
    "                             img_size=32, patch_size=4, embed_dim=192, depth=depth,\n",
    "                             num_heads=3, mlp_ratio=mlp_ratio, qkv_bias=True,\n",
    "                             drop_path_rate=0.1)\n",
    "\n",
    "# ------------------- 4. Load All Checkpoints -------------------\n",
    "pattern = f\"{OUTPUT_DIR}/outputvit_d*_mlp*_noise*.pth\"\n",
    "ckpt_paths = sorted(glob.glob(pattern))\n",
    "print(f\"Found {len(ckpt_paths)} checkpoints\")\n",
    "\n",
    "def parse_ckpt(p):\n",
    "    m = re.search(r'outputvit_d(\\d+)_mlp([\\d\\.]+)_noise([\\d\\.]+)\\.pth', os.path.basename(p))\n",
    "    return int(m.group(1)), float(m.group(2)), float(m.group(3))\n",
    "\n",
    "# ------------------- 5. Full Metrics Function -------------------\n",
    "def evaluate_full_metrics(model, loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            logits = model(x)\n",
    "            probs = torch.softmax(logits, dim=1)\n",
    "            pred = logits.max(1)[1]\n",
    "\n",
    "            all_preds.extend(pred.cpu().numpy())\n",
    "            all_labels.extend(y.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "    # Convert to numpy\n",
    "    y_true = np.array(all_labels)\n",
    "    y_pred = np.array(all_preds)\n",
    "    y_prob = np.array(all_probs)\n",
    "\n",
    "    # Accuracy\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    # AUC (macro + 95% CI via bootstrap)\n",
    "    def bootstrap_auc(n=1000):\n",
    "        aucs = []\n",
    "        for _ in range(n):\n",
    "            idx = np.random.choice(len(y_true), len(y_true), replace=True)\n",
    "            try:\n",
    "                aucs.append(roc_auc_score(y_true[idx], y_prob[idx], average='macro', multi_class='ovr'))\n",
    "            except:\n",
    "                pass\n",
    "        return np.array(aucs)\n",
    "\n",
    "    auc_boot = bootstrap_auc()\n",
    "    auc_mean = auc_boot.mean()\n",
    "    auc_ci = (auc_mean - 1.96 * sem(auc_boot), auc_mean + 1.96 * sem(auc_boot))\n",
    "\n",
    "    # Precision, Recall, F1 (macro)\n",
    "    p, r, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
    "\n",
    "    return {\n",
    "        'accuracy': acc * 100,\n",
    "        'auc_mean': auc_mean * 100,\n",
    "        'auc_ci_low': auc_ci[0] * 100,\n",
    "        'auc_ci_high': auc_ci[1] * 100,\n",
    "        'precision': p * 100,\n",
    "        'recall': r * 100,\n",
    "        'f1': f1 * 100\n",
    "    }\n",
    "\n",
    "# ------------------- 6. Evaluate All Models -------------------\n",
    "rows = []\n",
    "print(\"Evaluating all models with full metrics...\")\n",
    "for p in tqdm(ckpt_paths, desc=\"Models\"):\n",
    "    depth, mlp, noise = parse_ckpt(p)\n",
    "    model = create_vit_model(depth, mlp)\n",
    "    model.load_state_dict(torch.load(p, map_location=device))\n",
    "    model.to(device)\n",
    "\n",
    "    metrics = evaluate_full_metrics(model, test_loader)\n",
    "    params = sum(par.numel() for par in model.parameters())\n",
    "\n",
    "    rows.append({\n",
    "        \"train_noise\": noise,\n",
    "        \"depth\": depth,\n",
    "        \"mlp_ratio\": mlp,\n",
    "        \"params\": params,\n",
    "        **metrics\n",
    "    })\n",
    "\n",
    "    del model; torch.cuda.empty_cache()\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "csv_path = f\"{OUTPUT_DIR}/vit_grid_full_metrics.csv\"\n",
    "df.to_csv(csv_path, index=False)\n",
    "print(f\"\\nFull metrics CSV saved → {csv_path}\")\n",
    "\n",
    "# ------------------- 7. Feature 1: Noisy Image Visualization -------------------\n",
    "def plot_noisy_samples(noise_levels=[round(x, 2) for x in np.linspace(0.0, 1.0, 21)] ):\n",
    "    n_noise = len(noise_levels)\n",
    "    fig, axes = plt.subplots(10, 2 + n_noise, figsize=(3*(2+n_noise), 20))\n",
    "    fig.suptitle(\"CIFAR-10: Original vs Noisy Images\", fontsize=16, fontweight='bold')\n",
    "\n",
    "    for cls in range(10):\n",
    "        idx = cls * 2\n",
    "        img = vis_images[idx]  # one sample per class\n",
    "        axes[cls, 0].imshow(denormalize(img).permute(1,2,0).numpy())\n",
    "        axes[cls, 0].set_title(f\"Class {cls} - Clean\")\n",
    "        axes[cls, 0].axis('off')\n",
    "\n",
    "        axes[cls, 1].imshow(denormalize(img).permute(1,2,0).numpy())\n",
    "        axes[cls, 1].set_title(\"Clean (dup)\")\n",
    "        axes[cls, 1].axis('off')\n",
    "\n",
    "        for j, sigma in enumerate(noise_levels):\n",
    "            noisy = add_noise_in_rgb_space(img.unsqueeze(0), sigma).squeeze(0)\n",
    "            axes[cls, 2+j].imshow(denormalize(noisy).permute(1,2,0).numpy())\n",
    "            axes[cls, 2+j].set_title(f\"σ={sigma}\")\n",
    "            axes[cls, 2+j].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    out = f\"{OUTPUT_DIR}/noisy_image_examples.png\"\n",
    "    plt.savefig(out, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Noisy image grid saved → {out}\")\n",
    "\n",
    "plot_noisy_samples()\n",
    "\n",
    "# ------------------- 8. Feature 3: Interactive 3D Surface (Plotly) -------------------\n",
    "def interactive_3d_surfaces(df):\n",
    "    df_clean = df[df['test_noise'].isna() | (df['test_noise'] == 0.0)]\n",
    "    for noise in sorted(df_clean['train_noise'].unique()):\n",
    "        sub = df_clean[df_clean['train_noise'] == noise]\n",
    "        depths = sorted(sub['depth'].unique())\n",
    "        mlps = sorted(sub['mlp_ratio'].unique())\n",
    "\n",
    "        Z = sub.pivot(index='mlp_ratio', columns='depth', values='accuracy')\n",
    "        Z = Z.reindex(mlps).reindex(depths, axis=1).values\n",
    "\n",
    "        fig = go.Figure(data=[go.Surface(\n",
    "            x=depths, y=mlps, z=Z,\n",
    "            colorscale='Viridis', showscale=True\n",
    "        )])\n",
    "\n",
    "        fig.update_layout(\n",
    "            title=f'Accuracy Surface – train_noise={noise}',\n",
    "            scene=dict(\n",
    "                xaxis_title='Depth',\n",
    "                yaxis_title='MLP Ratio',\n",
    "                zaxis_title='Accuracy (%)',\n",
    "                camera=dict(eye=dict(x=1.5, y=1.5, z=1.5))\n",
    "            ),\n",
    "            width=800, height=600\n",
    "        )\n",
    "\n",
    "        out_html = f\"{OUTPUT_DIR}/3d_surface_noise_{noise}.html\"\n",
    "        fig.write_html(out_html)\n",
    "        print(f\"Interactive 3D plot → {out_html}\")\n",
    "\n",
    "interactive_3d_surfaces(df)\n",
    "\n",
    "# ------------------- 9. Summary Table (Best per Noise) -------------------\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BEST MODEL PER NOISE LEVEL (Accuracy)\")\n",
    "print(\"=\"*80)\n",
    "summary = []\n",
    "for noise in sorted(df['train_noise'].unique()):\n",
    "    sub = df[df['train_noise'] == noise]\n",
    "    best = sub.loc[sub['accuracy'].idxmax()]\n",
    "    summary.append({\n",
    "        'train_noise': noise,\n",
    "        'depth': int(best['depth']),\n",
    "        'mlp_ratio': best['mlp_ratio'],\n",
    "        'accuracy': best['accuracy'],\n",
    "        'auc': f\"{best['auc_mean']:.1f} [{best['auc_ci_low']:.1f}-{best['auc_ci_high']:.1f}]\",\n",
    "        'f1': best['f1']\n",
    "    })\n",
    "print(pd.DataFrame(summary).round(2).to_string(index=False))\n",
    "\n",
    "# ------------------- 10. Save Final Report -------------------\n",
    "report = {\n",
    "    \"analysis_date\": datetime.now().isoformat(),\n",
    "    \"total_models\": len(df),\n",
    "    \"metrics_included\": [\"accuracy\", \"auc+ci\", \"precision\", \"recall\", \"f1\"],\n",
    "    \"visualizations\": {\n",
    "        \"noisy_images\": \"noisy_image_examples.png\",\n",
    "        \"interactive_3d\": [f\"3d_surface_noise_{n}.html\" for n in sorted(df['train_noise'].unique())]\n",
    "    }\n",
    "}\n",
    "with open(f\"{OUTPUT_DIR}/final_report.json\", \"w\") as f:\n",
    "    json.dump(report, f, indent=2)\n",
    "print(f\"\\nFinal report → {OUTPUT_DIR}/final_report.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After final result csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded /home/akshy_grp12/vit_grid_full_metrics.csv with shape (904, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_noise</th>\n",
       "      <th>depth</th>\n",
       "      <th>mlp_ratio</th>\n",
       "      <th>params</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>auc_mean</th>\n",
       "      <th>auc_ci_low</th>\n",
       "      <th>auc_ci_high</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1885834</td>\n",
       "      <td>76.43</td>\n",
       "      <td>97.220481</td>\n",
       "      <td>97.215480</td>\n",
       "      <td>97.225481</td>\n",
       "      <td>76.344816</td>\n",
       "      <td>76.43</td>\n",
       "      <td>76.351263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1885834</td>\n",
       "      <td>71.46</td>\n",
       "      <td>96.307453</td>\n",
       "      <td>96.301493</td>\n",
       "      <td>96.313414</td>\n",
       "      <td>72.097264</td>\n",
       "      <td>71.46</td>\n",
       "      <td>71.492391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1885834</td>\n",
       "      <td>64.65</td>\n",
       "      <td>94.677601</td>\n",
       "      <td>94.670317</td>\n",
       "      <td>94.684884</td>\n",
       "      <td>67.447595</td>\n",
       "      <td>64.65</td>\n",
       "      <td>64.910215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.15</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1885834</td>\n",
       "      <td>62.78</td>\n",
       "      <td>94.146822</td>\n",
       "      <td>94.139002</td>\n",
       "      <td>94.154642</td>\n",
       "      <td>66.971154</td>\n",
       "      <td>62.78</td>\n",
       "      <td>63.075495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.20</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1885834</td>\n",
       "      <td>57.71</td>\n",
       "      <td>92.995612</td>\n",
       "      <td>92.987221</td>\n",
       "      <td>93.004003</td>\n",
       "      <td>62.677448</td>\n",
       "      <td>57.71</td>\n",
       "      <td>58.166470</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_noise  depth  mlp_ratio   params  accuracy   auc_mean  auc_ci_low  \\\n",
       "0         0.00     10        0.5  1885834     76.43  97.220481   97.215480   \n",
       "1         0.05     10        0.5  1885834     71.46  96.307453   96.301493   \n",
       "2         0.10     10        0.5  1885834     64.65  94.677601   94.670317   \n",
       "3         0.15     10        0.5  1885834     62.78  94.146822   94.139002   \n",
       "4         0.20     10        0.5  1885834     57.71  92.995612   92.987221   \n",
       "\n",
       "   auc_ci_high  precision  recall         f1  \n",
       "0    97.225481  76.344816   76.43  76.351263  \n",
       "1    96.313414  72.097264   71.46  71.492391  \n",
       "2    94.684884  67.447595   64.65  64.910215  \n",
       "3    94.154642  66.971154   62.78  63.075495  \n",
       "4    93.004003  62.677448   57.71  58.166470  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd, numpy as np, os\n",
    "OUTPUT_DIR = \"/home/akshy_grp12\"   # keep your same output dir\n",
    "csv_path = os.path.join(OUTPUT_DIR, \"vit_grid_full_metrics.csv\")\n",
    "df = pd.read_csv(csv_path)\n",
    "print(\"Loaded\", csv_path, \"with shape\", df.shape)\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/akshy_grp12/vit_line_2.png\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_line(df):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    for d in sorted(df['depth'].unique()):\n",
    "        sub = df[df['depth']==d].sort_values('train_noise')\n",
    "        plt.plot(sub['train_noise'], sub['accuracy'], marker='o', label=f'Depth {d}')\n",
    "    plt.xlabel('Train Noise'); plt.ylabel('Clean Test Acc (%)')\n",
    "    plt.title('ViT Accuracy vs Training Noise')\n",
    "    plt.legend(); plt.grid(alpha=.3)\n",
    "    out = os.path.join(OUTPUT_DIR, \"vit_line_2.png\")\n",
    "    plt.savefig(out, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"Saved:\", out)\n",
    "\n",
    "plot_line(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/akshy_grp12/surface_noise_0.0.png\n",
      "Saved: /home/akshy_grp12/surface_noise_0.05.png\n",
      "Saved: /home/akshy_grp12/surface_noise_0.1.png\n",
      "Saved: /home/akshy_grp12/surface_noise_0.15.png\n",
      "Saved: /home/akshy_grp12/surface_noise_0.2.png\n",
      "Saved: /home/akshy_grp12/surface_noise_0.25.png\n",
      "Saved: /home/akshy_grp12/surface_noise_0.3.png\n",
      "Saved: /home/akshy_grp12/surface_noise_0.35.png\n",
      "Saved: /home/akshy_grp12/surface_noise_0.4.png\n",
      "Saved: /home/akshy_grp12/surface_noise_0.45.png\n"
     ]
    }
   ],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "def static_surface_plots(df):\n",
    "    df_clean = df.copy()\n",
    "    if 'test_noise' in df.columns:\n",
    "        df_clean = df_clean[df_clean['test_noise'].isna() | (df_clean['test_noise']==0.0)]\n",
    "    for nv in sorted(df_clean['train_noise'].unique()):\n",
    "        sub = df_clean[df_clean['train_noise']==nv]\n",
    "        depths = sorted(sub['depth'].unique())\n",
    "        mlps   = sorted(sub['mlp_ratio'].unique())\n",
    "        Z = sub.pivot(index='mlp_ratio', columns='depth', values='accuracy')\n",
    "        Z = Z.reindex(index=mlps, columns=depths).values\n",
    "\n",
    "        fig = plt.figure(figsize=(8,6))\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "        X, Y = np.meshgrid(depths, mlps)\n",
    "        ax.plot_surface(X, Y, Z, cmap='viridis', edgecolor='none', alpha=0.9)\n",
    "        ax.set_xlabel('Depth'); ax.set_ylabel('MLP Ratio'); ax.set_zlabel('Acc (%)')\n",
    "        ax.set_title(f'Accuracy Surface – train_noise={nv}')\n",
    "        out = os.path.join(OUTPUT_DIR, f\"surface_noise_{nv}.png\")\n",
    "        plt.savefig(out, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(\"Saved:\", out)\n",
    "\n",
    "static_surface_plots(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved interactive: /home/akshy_grp12/3d_surface_noise_0.0.html\n",
      "Saved interactive: /home/akshy_grp12/3d_surface_noise_0.05.html\n",
      "Saved interactive: /home/akshy_grp12/3d_surface_noise_0.1.html\n",
      "Saved interactive: /home/akshy_grp12/3d_surface_noise_0.15.html\n",
      "Saved interactive: /home/akshy_grp12/3d_surface_noise_0.2.html\n",
      "Saved interactive: /home/akshy_grp12/3d_surface_noise_0.25.html\n",
      "Saved interactive: /home/akshy_grp12/3d_surface_noise_0.3.html\n",
      "Saved interactive: /home/akshy_grp12/3d_surface_noise_0.35.html\n",
      "Saved interactive: /home/akshy_grp12/3d_surface_noise_0.4.html\n",
      "Saved interactive: /home/akshy_grp12/3d_surface_noise_0.45.html\n"
     ]
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "def interactive_3d_surfaces(df):\n",
    "    df_clean = df.copy()\n",
    "    if 'test_noise' in df.columns:\n",
    "        df_clean = df_clean[df_clean['test_noise'].isna() | (df_clean['test_noise']==0.0)]\n",
    "    for noise in sorted(df_clean['train_noise'].unique()):\n",
    "        sub = df_clean[df_clean['train_noise'] == noise]\n",
    "        depths = sorted(sub['depth'].unique())\n",
    "        mlps   = sorted(sub['mlp_ratio'].unique())\n",
    "\n",
    "        Z = sub.pivot(index='mlp_ratio', columns='depth', values='accuracy')\n",
    "        Z = Z.reindex(index=mlps, columns=depths).values\n",
    "\n",
    "        fig = go.Figure(data=[go.Surface(\n",
    "            x=depths, y=mlps, z=Z,\n",
    "            colorscale='Viridis', showscale=True\n",
    "        )])\n",
    "\n",
    "        fig.update_layout(\n",
    "            title=f'Accuracy Surface – train_noise={noise}',\n",
    "            scene=dict(\n",
    "                xaxis_title='Depth',\n",
    "                yaxis_title='MLP Ratio',\n",
    "                zaxis_title='Accuracy (%)',\n",
    "                camera=dict(eye=dict(x=1.5, y=1.5, z=1.5))\n",
    "            ),\n",
    "            width=900, height=700\n",
    "        )\n",
    "\n",
    "        out_html = os.path.join(OUTPUT_DIR, f\"3d_surface_noise_{noise}.html\")\n",
    "        fig.write_html(out_html)\n",
    "        print(\"Saved interactive:\", out_html)\n",
    "\n",
    "interactive_3d_surfaces(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train_noise  depth  mlp_ratio  accuracy  auc_mean     f1\n",
      "        0.00      8        3.0     79.43    97.748 79.379\n",
      "        0.05     10        3.5     75.54    97.090 75.646\n",
      "        0.10     14        1.0     69.08    95.837 69.327\n",
      "        0.15     10        1.0     63.86    94.412 64.202\n",
      "        0.20     12        0.5     59.29    93.199 59.619\n",
      "        0.25     16        0.5     57.42    92.243 57.683\n",
      "        0.30     14        1.0     54.25    91.061 54.800\n",
      "        0.35     14        0.5     54.58    90.872 54.647\n",
      "        0.40      8        0.5     52.11    90.200 52.230\n",
      "        0.45      6        1.0     49.48    88.893 49.265\n",
      "Saved best-per-noise CSV\n"
     ]
    }
   ],
   "source": [
    "summary = []\n",
    "for noise in sorted(df['train_noise'].unique()):\n",
    "    sub = df[df['train_noise'] == noise]\n",
    "    best = sub.loc[sub['accuracy'].idxmax()]\n",
    "    summary.append({\n",
    "        'train_noise': noise,\n",
    "        'depth': int(best['depth']),\n",
    "        'mlp_ratio': best['mlp_ratio'],\n",
    "        'accuracy': best['accuracy'],\n",
    "        'auc_mean': best.get('auc_mean', np.nan),\n",
    "        'f1': best.get('f1', np.nan)\n",
    "    })\n",
    "best_df = pd.DataFrame(summary).round(3)\n",
    "print(best_df.to_string(index=False))\n",
    "best_df.to_csv(os.path.join(OUTPUT_DIR, \"best_per_noise.csv\"), index=False)\n",
    "print(\"Saved best-per-noise CSV\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/akshy_grp12/heatmap_noise_0.0.png\n",
      "Saved: /home/akshy_grp12/heatmap_noise_0.05.png\n",
      "Saved: /home/akshy_grp12/heatmap_noise_0.1.png\n",
      "Saved: /home/akshy_grp12/heatmap_noise_0.15.png\n",
      "Saved: /home/akshy_grp12/heatmap_noise_0.2.png\n",
      "Saved: /home/akshy_grp12/heatmap_noise_0.25.png\n",
      "Saved: /home/akshy_grp12/heatmap_noise_0.3.png\n",
      "Saved: /home/akshy_grp12/heatmap_noise_0.35.png\n",
      "Saved: /home/akshy_grp12/heatmap_noise_0.4.png\n",
      "Saved: /home/akshy_grp12/heatmap_noise_0.45.png\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "def heatmaps_per_noise(df):\n",
    "    try:\n",
    "        import seaborn as sns\n",
    "    except:\n",
    "        import sys\n",
    "        !{sys.executable} -m pip install seaborn\n",
    "        import seaborn as sns\n",
    "\n",
    "    for nv in sorted(df['train_noise'].unique()):\n",
    "        sub = df[df['train_noise']==nv]\n",
    "        Z = sub.pivot(index='mlp_ratio', columns='depth', values='accuracy')\n",
    "        plt.figure(figsize=(8,6))\n",
    "        sns.heatmap(Z, annot=True, fmt=\".2f\", cbar_kws={'label':'Acc (%)'})\n",
    "        plt.title(f\"Heatmap Acc — train_noise={nv}\")\n",
    "        plt.xlabel('Depth'); plt.ylabel('MLP Ratio')\n",
    "        out = os.path.join(OUTPUT_DIR, f\"heatmap_noise_{nv}.png\")\n",
    "        plt.savefig(out, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(\"Saved:\", out)\n",
    "\n",
    "heatmaps_per_noise(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
